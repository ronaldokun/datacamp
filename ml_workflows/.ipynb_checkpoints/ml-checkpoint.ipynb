{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(200,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=chapter2.pdf width=720 height=480></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{chapter2.pdf}"
      ],
      "text/plain": [
       "<__main__.PDF at 0x2037dd71248>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF('chapter2.pdf',size=(720, 480))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Expert Knowledge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = pd.read_csv('lanl_flows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"exercise--title\">Is the source or the destination bad?</h1><div class=\"\"><p>In the previous lesson, you used the <em>destination</em> computer as your entity of interest. However, your cybersecurity analyst just told you that it is the infected machines that generate the bad traffic, and will therefore appear as a <em>source</em>, not a destination, in the <code>flows</code> dataset. </p>\n",
    "<p>The data <code>flows</code> has been preloaded, as well as the list <code>bad</code> of infected IDs and the feature extractor <code>featurizer()</code> from the previous lesson. You also have <code>numpy</code> available as <code>np</code>, <code>AdaBoostClassifier()</code>, and <code>cross_val_score()</code>.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(df):\n",
    "    return {\n",
    "        'unique_ports': len(set(df['destination_port'])),\n",
    "        'average_packet': np.mean(df['packet_count']),\n",
    "        'average_duration': np.mean(df['duration'])\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = {'C1', 'C10', 'C10005', 'C1003', 'C1006', 'C1014', 'C1015',\n",
    " 'C102', 'C1022', 'C1028', 'C10405', 'C1042', 'C1046', 'C10577',\n",
    " 'C1065', 'C108', 'C10817', 'C1085', 'C1089', 'C1096', 'C11039',\n",
    " 'C11178', 'C1119', 'C11194', 'C1124', 'C1125', 'C113', 'C115', \n",
    " 'C11727', 'C1173', 'C1183', 'C1191', 'C12116', 'C1215', 'C1222',\n",
    " 'C1224', 'C12320', 'C12448', 'C12512', 'C126', 'C1268', 'C12682',\n",
    " 'C1269', 'C1275', 'C1302', 'C1319', 'C13713', 'C1382', 'C1415',\n",
    " 'C143', 'C1432', 'C1438', 'C1448', 'C1461', 'C1477', 'C1479', 'C148',\n",
    " 'C1482', 'C1484', 'C1493', 'C15', 'C1500', 'C1503', 'C1506', 'C1509',\n",
    " 'C15197', 'C152', 'C15232', 'C1549', 'C155', 'C1555', 'C1567', 'C1570',\n",
    " 'C1581', 'C16088', 'C1610', 'C1611', 'C1616', 'C1626', 'C1632', 'C16401',\n",
    " 'C16467', 'C16563', 'C1710', 'C1732', 'C1737', 'C17425', 'C17600', 'C17636',\n",
    " 'C17640', 'C17693', 'C177', 'C1776', 'C17776', 'C17806', 'C1784', 'C17860',\n",
    " 'C1797', 'C18025', 'C1810', 'C18113', 'C18190', 'C1823', 'C18464', 'C18626',\n",
    " 'C1887', 'C18872', 'C19038', 'C1906', 'C19156', 'C19356', 'C1936', 'C1944',\n",
    " 'C19444', 'C1952', 'C1961', 'C1964', 'C1966', 'C1980', 'C19803', 'C19932',\n",
    " 'C2012',\n",
    " 'C2013',\n",
    " 'C20203',\n",
    " 'C20455',\n",
    " 'C2057',\n",
    " 'C2058',\n",
    " 'C20677',\n",
    " 'C2079',\n",
    " 'C20819',\n",
    " 'C2085',\n",
    " 'C2091',\n",
    " 'C20966',\n",
    " 'C21349',\n",
    " 'C21664',\n",
    " 'C21814',\n",
    " 'C21919',\n",
    " 'C21946',\n",
    " 'C2196',\n",
    " 'C21963',\n",
    " 'C22174',\n",
    " 'C22176',\n",
    " 'C22275',\n",
    " 'C22409',\n",
    " 'C2254',\n",
    " 'C22766',\n",
    " 'C231',\n",
    " 'C2341',\n",
    " 'C2378',\n",
    " 'C2388',\n",
    " 'C243',\n",
    " 'C246',\n",
    " 'C2519',\n",
    " 'C2578',\n",
    " 'C2597',\n",
    " 'C2604',\n",
    " 'C2609',\n",
    " 'C2648',\n",
    " 'C2669',\n",
    " 'C2725',\n",
    " 'C2816',\n",
    " 'C2844',\n",
    " 'C2846',\n",
    " 'C2849',\n",
    " 'C2877',\n",
    " 'C2914',\n",
    " 'C294',\n",
    " 'C2944',\n",
    " 'C3019',\n",
    " 'C302',\n",
    " 'C3037',\n",
    " 'C305',\n",
    " 'C306',\n",
    " 'C307',\n",
    " 'C313',\n",
    " 'C3153',\n",
    " 'C3170',\n",
    " 'C3173',\n",
    " 'C3199',\n",
    " 'C3249',\n",
    " 'C3288',\n",
    " 'C3292',\n",
    " 'C3303',\n",
    " 'C3305',\n",
    " 'C332',\n",
    " 'C338',\n",
    " 'C3380',\n",
    " 'C3388',\n",
    " 'C3422',\n",
    " 'C3435',\n",
    " 'C3437',\n",
    " 'C3455',\n",
    " 'C346',\n",
    " 'C3491',\n",
    " 'C3521',\n",
    " 'C353',\n",
    " 'C3586',\n",
    " 'C359',\n",
    " 'C3597',\n",
    " 'C3601',\n",
    " 'C3610',\n",
    " 'C3629',\n",
    " 'C3635',\n",
    " 'C366',\n",
    " 'C368',\n",
    " 'C3699',\n",
    " 'C370',\n",
    " 'C3755',\n",
    " 'C3758',\n",
    " 'C3813',\n",
    " 'C385',\n",
    " 'C3888',\n",
    " 'C395',\n",
    " 'C398',\n",
    " 'C400',\n",
    " 'C4106',\n",
    " 'C4159',\n",
    " 'C4161',\n",
    " 'C42',\n",
    " 'C423',\n",
    " 'C4280',\n",
    " 'C429',\n",
    " 'C430',\n",
    " 'C4403',\n",
    " 'C452',\n",
    " 'C4554',\n",
    " 'C457',\n",
    " 'C458',\n",
    " 'C46',\n",
    " 'C4610',\n",
    " 'C464',\n",
    " 'C467',\n",
    " 'C477',\n",
    " 'C4773',\n",
    " 'C4845',\n",
    " 'C486',\n",
    " 'C492',\n",
    " 'C4934',\n",
    " 'C5030',\n",
    " 'C504',\n",
    " 'C506',\n",
    " 'C5111',\n",
    " 'C513',\n",
    " 'C52',\n",
    " 'C528',\n",
    " 'C529',\n",
    " 'C5343',\n",
    " 'C5439',\n",
    " 'C5453',\n",
    " 'C553',\n",
    " 'C5618',\n",
    " 'C5653',\n",
    " 'C5693',\n",
    " 'C583',\n",
    " 'C586',\n",
    " 'C61',\n",
    " 'C612',\n",
    " 'C625',\n",
    " 'C626',\n",
    " 'C633',\n",
    " 'C636',\n",
    " 'C6487',\n",
    " 'C6513',\n",
    " 'C685',\n",
    " 'C687',\n",
    " 'C706',\n",
    " 'C7131',\n",
    " 'C721',\n",
    " 'C728',\n",
    " 'C742',\n",
    " 'C7464',\n",
    " 'C7503',\n",
    " 'C754',\n",
    " 'C7597',\n",
    " 'C765',\n",
    " 'C7782',\n",
    " 'C779',\n",
    " 'C78',\n",
    " 'C791',\n",
    " 'C798',\n",
    " 'C801',\n",
    " 'C8172',\n",
    " 'C8209',\n",
    " 'C828',\n",
    " 'C849',\n",
    " 'C8490',\n",
    " 'C853',\n",
    " 'C8585',\n",
    " 'C8751',\n",
    " 'C881',\n",
    " 'C882',\n",
    " 'C883',\n",
    " 'C886',\n",
    " 'C89',\n",
    " 'C90',\n",
    " 'C9006',\n",
    " 'C917',\n",
    " 'C92',\n",
    " 'C923',\n",
    " 'C96',\n",
    " 'C965',\n",
    " 'C9692',\n",
    " 'C9723',\n",
    " 'C977',\n",
    " 'C9945'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by source computer, and apply the feature extractor\n",
    "out = flows.groupby('source_computer').apply(featurize)\n",
    "\n",
    "# Convert the iterator to a dataframe by calling list on it\n",
    "X = pd.DataFrame(list(out), index=out.index)\n",
    "\n",
    "# Check which sources in X.index are bad to create labels\n",
    "y = [x in bads for x in X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ports</th>\n",
       "      <th>average_packet</th>\n",
       "      <th>average_duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_computer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>4</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10026</th>\n",
       "      <td>2</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10047</th>\n",
       "      <td>5</td>\n",
       "      <td>21.076923</td>\n",
       "      <td>7.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1015</th>\n",
       "      <td>35</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>27.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10235</th>\n",
       "      <td>1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 unique_ports  average_packet  average_duration\n",
       "source_computer                                                \n",
       "C10                         4      222.000000          5.000000\n",
       "C10026                      2       21.000000         39.000000\n",
       "C10047                      5       21.076923          7.538462\n",
       "C1015                      35        5.371429         27.571429\n",
       "C10235                      1       11.000000          0.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "# Report the average accuracy of Adaboost over 3-fold CV\n",
    "\n",
    "print(np.mean(cross_val_score(AdaBoostClassifier(), X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"exercise--title\">Feature engineering on grouped data</h1><div class=\"\"><p>You will now build on the previous exercise, by considering one additional feature: the number of unique protocols used by each source computer. Note that with grouped data, it is always possible to construct features in this manner: you can take the number of unique elements of all categorical columns, and the mean of all numeric columns as your starting point. As before, you have <code>flows</code> preloaded, <code>cross_val_score()</code> for measuring accuracy, <code>AdaBoostClassifier()</code>, <code>pandas</code> as <code>pd</code> and <code>numpy</code> as <code>np</code>.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "# Create a feature counting unique protocols per source\n",
    "protocols = flows.groupby('source_computer').apply(lambda df: len(set(df.protocol)))\n",
    "\n",
    "# Convert this feature into a dataframe, naming the column\n",
    "protocols_DF = pd.DataFrame(protocols, index=protocols.index, columns=['protocol'])\n",
    "\n",
    "# Now concatenate this feature with the previous dataset, X\n",
    "X_more = pd.concat([X, protocols_DF], axis=1)\n",
    "\n",
    "# Refit the classifier and report its accuracy\n",
    "print(np.mean(cross_val_score(AdaBoostClassifier(), X_more, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"exercise--title\">Turning a heuristic into a classifier</h1><div class=\"\"><p>You are surprised by the fact that heuristics can be so helpful. So you decide to treat the heuristic that \"too many unique ports is suspicious\" as a classifier in its own right. You achieve that by thresholding the number of unique ports per source by the average number used in bad source computers -- these are computers for which the label is <code>True</code>. The dataset is preloaded and split into training and test, so you have objects <code>X_train</code>, <code>X_test</code>, <code>y_train</code> and <code>y_test</code> in memory. Your imports include <code>accuracy_score()</code>, and <code>numpy</code> as <code>np</code>. To clarify: you won't be fitting a classifier from scikit-learn in this exercise, but instead you will define your own classification rule explicitly!</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959731543624161\n"
     ]
    }
   ],
   "source": [
    "#Create a new dataset `X_train_bad` by subselecting bad hosts\n",
    "\n",
    "X_train_bad = X_train[y_train]\n",
    "\n",
    "#Calculate the average of `unique_ports` in bad examples\n",
    "\n",
    "avg_bad_ports = np.mean(X_train_bad.unique_ports)\n",
    "\n",
    "#Label as positive sources that use more ports than that\n",
    "\n",
    "pred_port = X_test['unique_ports'] > avg_bad_ports\n",
    "\n",
    "#Print the `accuracy_score` of the heuristic\n",
    "\n",
    "print(accuracy_score(y_test, pred_port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacamp",
   "language": "python",
   "name": "datacamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
